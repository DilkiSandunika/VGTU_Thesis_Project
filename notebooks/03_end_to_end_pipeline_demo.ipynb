{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNm+TGiKoZ01lxZEWborY72",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8621a95e66704e29ab06ce21dffd76b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44a8865b8aec4d349b24036735b67868",
              "IPY_MODEL_89c554f5bb5b40bfb24b983b17a20a4d",
              "IPY_MODEL_ab3fd22f83fa40789e3992d535455e07"
            ],
            "layout": "IPY_MODEL_2bf90ce126eb4de493993d56c4f0f0fe"
          }
        },
        "44a8865b8aec4d349b24036735b67868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffcc17377277489ba36561b5b3578926",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e000f38b69406db8bd9a76a7190151",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "89c554f5bb5b40bfb24b983b17a20a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab490be5a4045f4bf7b517d2b5e76da",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f481bfc9acc41c69f444c966464097f",
            "value": 2
          }
        },
        "ab3fd22f83fa40789e3992d535455e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2dba66ff21a4ee28f76438b52259d2a",
            "placeholder": "​",
            "style": "IPY_MODEL_2ceca47d95e745c9a3458d02f5faba9f",
            "value": " 2/2 [00:12&lt;00:00,  5.00s/it]"
          }
        },
        "2bf90ce126eb4de493993d56c4f0f0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffcc17377277489ba36561b5b3578926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e000f38b69406db8bd9a76a7190151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ab490be5a4045f4bf7b517d2b5e76da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f481bfc9acc41c69f444c966464097f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2dba66ff21a4ee28f76438b52259d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ceca47d95e745c9a3458d02f5faba9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DilkiSandunika/VGTU_Thesis_Project/blob/main/notebooks/03_end_to_end_pipeline_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BXcNOWFD5sDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8621a95e66704e29ab06ce21dffd76b6",
            "44a8865b8aec4d349b24036735b67868",
            "89c554f5bb5b40bfb24b983b17a20a4d",
            "ab3fd22f83fa40789e3992d535455e07",
            "2bf90ce126eb4de493993d56c4f0f0fe",
            "ffcc17377277489ba36561b5b3578926",
            "c3e000f38b69406db8bd9a76a7190151",
            "4ab490be5a4045f4bf7b517d2b5e76da",
            "1f481bfc9acc41c69f444c966464097f",
            "b2dba66ff21a4ee28f76438b52259d2a",
            "2ceca47d95e745c9a3458d02f5faba9f"
          ]
        },
        "outputId": "af4fef5b-bf23-42aa-b677-52477649b01a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required libraries for the full RAG pipeline with Gemma...\n",
            "Libraries installed successfully.\n",
            "Hugging Face token loaded successfully.\n",
            "Successfully logged in to Hugging Face.\n",
            "\n",
            "Loading all necessary components...\n",
            "Loaded 115 requirements from the CSV file.\n",
            "Loaded FAISS index and knowledge base documents.\n",
            "Sentence Transformer model loaded.\n",
            "\n",
            "Loading Google Gemma model... This will take a few minutes and use significant RAM.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8621a95e66704e29ab06ce21dffd76b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Gemma model loaded successfully!\n",
            "\n",
            "--- Setup is complete and all components are ready! ---\n",
            "=====================================================================\n",
            "  RUNNING RAG PIPELINE to generate 10 (X, y) examples  \n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #1...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'The solution should provide detailed context-sensitive help material for all the possible actions and scenarios on all user interfaces in the application.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'entence:\n",
            "\n",
            "\"The application shall provide context-sensitive help materials for each user interface action and scenario, enabling users to understand and perform actions effectively.\"'\n",
            "\n",
            "[VALIDATION] Compliance Score: 1/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #2...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'The solution should provide detailed context-sensitive help material for all the possible actions and scenarios on all user interfaces in the application.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'entence:\n",
            "\n",
            "\"The application shall provide context-sensitive help materials for each user interface action and scenario, enabling users to understand and perform actions effectively.\"'\n",
            "\n",
            "[VALIDATION] Compliance Score: 1/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #3...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'The solution should provide an interface for the user to log any defects or enhancement requests on the application and track thereafter.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'entence:\n",
            "\n",
            "\"The user shall be able to submit and track defect or enhancement requests through an intuitive and user-friendly interface, enabling timely resolution.\"'\n",
            "\n",
            "[VALIDATION] Compliance Score: 1/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #4...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'The solution should send alerts (e.g., email, SMS) to the user if the user chooses to whenever any action has been taken on the alert.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'the system shall send alerts (e.g., email, SMS) to the user.'\n",
            "\n",
            "[VALIDATION] Compliance Score: 1/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #5...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'The solution should enable the user to track the submitted defect or enhancement request.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'entence:\n",
            "\n",
            "\"The user shall be able to access a log of submitted defect or enhancement requests and track their status.\"'\n",
            "\n",
            "[VALIDATION] Compliance Score: 1/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #6...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'The solution should enable the help-desk user to view the reports on the submitted defects or enhancement requests category-wise, status-wise, and age- wise.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'entence:\n",
            "\n",
            "\"The help-desk user shall be able to access reports categorized by submission category, status, and age, enabling them to gain insights into the submitted defects and enhancement requests.\"'\n",
            "\n",
            "[VALIDATION] Compliance Score: 1/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #7...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'The support solution should be accessible to the users both from within the application and also outside the application through a browser interface.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'\n",
            "\"The support solution shall be accessible from both the application and the browser, enabling users to access it seamlessly.\"'\n",
            "\n",
            "[VALIDATION] Compliance Score: 1/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #8...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'An audit trail is a record of actions taken by either the user or the system triggers. This includes actions taken by users or Administrators, or actions initiated automatically by the system as a result of system parameters. The System must keep an unalterable audit trail capable of automatically capturing and storing information about:All the actions (create/read/update/delete) that are taken upon the critical entities (case, suspect, property,...) in the systemThe user initiating and or carrying out the action;The date and time of the event.Administrative parametersThe word “unalterable” is to mean that the audit trail data cannot be modified in any way or deleted by any user; it may be subject to re-department and copying to removable media if required, so long as its contents remain unchanged.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'of actions taken by users or the system, capturing and storing information about the user initiating and carrying out the action, the date and time of the event, and any administrative parameters associated with the action.'\n",
            "\n",
            "[VALIDATION] Compliance Score: 0/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #9...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'Once the audit trail functionality has been activated, the System must track events without manual intervention, and store in the audit trail information about them.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "'ual intervention and store in the audit trail information about them, ensuring compliance with rule 103.'\n",
            "\n",
            "[VALIDATION] Compliance Score: 0/2\n",
            "=====================================================================\n",
            "\n",
            "\n",
            "Processing Requirement #10...\n",
            "---------------------------------------------------------------------\n",
            "[INPUT - X] Original:\n",
            "'The System must maintain the audit trail for as long as required, which will be at least for the life of the case to which it refers.'\n",
            "\n",
            "[OUTPUT - y] Refined:\n",
            "' for the life of the case, ensuring its integrity and accessibility for as long as required.'\n",
            "\n",
            "[VALIDATION] Compliance Score: 1/3\n",
            "=====================================================================\n",
            "\n",
            "Successfully generated and saved 10 (X, y) examples to '/content/X_y_examples.csv'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac1f720a-41eb-4554-91b4-fc7b85b6ab87\", \"X_y_examples.csv\", 6172)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================================================================\n",
            "       RUNNING RAG PIPELINE DEMO on the First 5 Requirements      \n",
            "=====================================================================\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# CELL 1: Install All Necessary Libraries\n",
        "# ===================================================================\n",
        "print(\"Installing required libraries for the full RAG pipeline with Gemma...\")\n",
        "# We need transformers and accelerate for Hugging Face models, and bitsandbytes for quantization\n",
        "!pip install pandas faiss-cpu sentence-transformers torch transformers accelerate bitsandbytes -q\n",
        "print(\"Libraries installed successfully.\")\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# CELL 2: Import Libraries and Log in to Hugging Face\n",
        "# ===================================================================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pickle\n",
        "from google.colab import userdata\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# Securely load the Hugging Face token from Colab secrets\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    print(\"Hugging Face token loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"ERROR: Could not load Hugging Face token. Please add it to Colab's secrets (key icon on the left) with the name HF_TOKEN.\")\n",
        "\n",
        "# Log in to Hugging Face Hub\n",
        "from huggingface_hub import login\n",
        "login(token=HF_TOKEN)\n",
        "print(\"Successfully logged in to Hugging Face.\")\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# CELL 3: Load All Pre-processed Data and Models\n",
        "# ===================================================================\n",
        "print(\"\\nLoading all necessary components...\")\n",
        "\n",
        "# --- 1. Load the Parsed Requirements ---\n",
        "df_requirements = pd.read_csv('/content/parsed_requirements.csv')\n",
        "print(f\"Loaded {len(df_requirements)} requirements from the CSV file.\")\n",
        "\n",
        "# --- 2. Load the Knowledge Base ---\n",
        "index = faiss.read_index('/content/knowledge_base.index')\n",
        "with open('/content/knowledge_base_docs.pkl', 'rb') as f:\n",
        "    knowledge_base_docs = pickle.load(f)\n",
        "print(\"Loaded FAISS index and knowledge base documents.\")\n",
        "\n",
        "# --- 3. Load the Sentence Transformer Model ---\n",
        "retrieval_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Sentence Transformer model loaded.\")\n",
        "\n",
        "# --- 4. Load the Gemma Model for Generation ---\n",
        "print(\"\\nLoading Google Gemma model... This will take a few minutes and use significant RAM.\")\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "gemma_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "print(\"Google Gemma model loaded successfully!\")\n",
        "print(\"\\n--- Setup is complete and all components are ready! ---\")\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# CELL 4: The RAG Core and Validation Functions\n",
        "# ===================================================================\n",
        "\n",
        "def retrieve_relevant_knowledge(query_text, top_k=3):\n",
        "    \"\"\"\n",
        "    Searches the FAISS index for the most relevant knowledge base documents for a given query.\n",
        "    \"\"\"\n",
        "    query_vector = retrieval_model.encode([query_text])\n",
        "    distances, indices = index.search(query_vector.astype('float32'), top_k)\n",
        "    retrieved_docs = [knowledge_base_docs[i] for i in indices[0]]\n",
        "    return retrieved_docs\n",
        "\n",
        "def generate_compliant_requirement_with_gemma(original_requirement, retrieved_docs):\n",
        "    \"\"\"\n",
        "    Builds a prompt and calls the Gemma model to generate a refined requirement.\n",
        "    \"\"\"\n",
        "    retrieved_knowledge = \"\\n- \".join(retrieved_docs)\n",
        "\n",
        "    # --- THIS IS THE UPGRADED PROMPT ---\n",
        "    chat = [\n",
        "        { \"role\": \"user\", \"content\": f\"\"\"\n",
        "You are an expert Software Requirements Analyst. Your task is to analyze an original requirement and rewrite it to be compliant with a set of standard formats.\n",
        "\n",
        "**Compliance Rules to Follow:**\n",
        "- {retrieved_knowledge}\n",
        "\n",
        "**Original Requirement to Analyze:**\n",
        "\"{original_requirement}\"\n",
        "\n",
        "**Your Task:**\n",
        "1.  First, analyze the intent of the original requirement.\n",
        "2.  Next, select the MOST APPROPRIATE format from the list of five standard formats provided in the compliance rules.\n",
        "3.  Finally, rewrite the original requirement to perfectly match your chosen format.\n",
        "\n",
        "Your entire response MUST be only the single, rewritten requirement sentence. Do not add any other text, preambles, or explanations about which format you chose.\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "    # --- END OF UPGRADED PROMPT ---\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = gemma_model.generate(input_ids=inputs, max_new_tokens=150)\n",
        "\n",
        "    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response_text[len(prompt)-7:]\n",
        "\n",
        "# def generate_compliant_requirement_with_gemma(original_requirement, retrieved_docs):\n",
        "#     \"\"\"\n",
        "#     Builds a prompt and calls the Gemma model to generate a refined requirement.\n",
        "#     \"\"\"\n",
        "#     retrieved_knowledge = \"\\n- \".join(retrieved_docs)\n",
        "\n",
        "#     chat = [\n",
        "#         { \"role\": \"user\", \"content\": f\"\"\"\n",
        "# You are an expert Software Requirements Analyst. Your task is to refine a given software requirement to ensure it is compliant with a set of rules and well-formed according to a template.\n",
        "\n",
        "# **Compliance Rules and Template Guide to Follow:**\n",
        "# - {retrieved_knowledge}\n",
        "\n",
        "# **Original Requirement to Refine:**\n",
        "# \"{original_requirement}\"\n",
        "\n",
        "# **Your Task:**\n",
        "# Rewrite the original requirement to be fully compliant with the rules provided above.\n",
        "# - Ensure the output strictly follows the format: \"The system shall [action description] for the [user role].\"\n",
        "# - Your response MUST begin with \"The system shall\" and be a single sentence. Do not add any other text, preambles, or explanations. Your entire response must be only the single, rewritten requirement.\n",
        "# \"\"\"\n",
        "#         }\n",
        "#     ]\n",
        "\n",
        "#     prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "#     inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "#     outputs = gemma_model.generate(input_ids=inputs, max_new_tokens=150)\n",
        "\n",
        "#     response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "#     return response_text[len(prompt)-7:]\n",
        "\n",
        "def calculate_compliance_score(generated_text, retrieved_rules):\n",
        "    \"\"\"\n",
        "    Calculates a compliance score based on a set of rules and multiple possible formats.\n",
        "    \"\"\"\n",
        "    feedback = []\n",
        "\n",
        "    # Define the valid requirement patterns\n",
        "    patterns = [\n",
        "        \"The <system name> shall <system response>\",\n",
        "        \"WHILE <in a specific state> the <system name> shall <system response>\",\n",
        "        \"WHEN <trigger> <optional precondition> the <system name> shall <system response>\",\n",
        "        \"WHERE <feature is included> the <system name> shall <system response>\",\n",
        "        \"IF <unwanted condition or event>, THEN the <system name> shall <system response>\"\n",
        "    ]\n",
        "\n",
        "    # --- Rule Check 1: Check for adherence to one of the standard formats ---\n",
        "    # We create simplified keywords to check for each pattern\n",
        "    pattern_keywords = [\n",
        "        \"The \", \"WHILE \", \"WHEN \", \"WHERE \", \"IF \"\n",
        "    ]\n",
        "\n",
        "    found_pattern = False\n",
        "    for keyword in pattern_keywords:\n",
        "        if generated_text.startswith(keyword):\n",
        "            found_pattern = True\n",
        "            break\n",
        "\n",
        "    if found_pattern:\n",
        "        feedback.append(\"PASS: Requirement follows one of the standard formats.\")\n",
        "    else:\n",
        "        feedback.append(\"FAIL: Requirement does not begin with a standard pattern keyword (The, WHILE, WHEN, WHERE, IF).\")\n",
        "\n",
        "    # --- Rule Check 2: Check for active voice ---\n",
        "    if any(\"active voice\" in rule for rule in retrieved_rules):\n",
        "        if \"should be\" not in generated_text:\n",
        "            feedback.append(\"PASS: Requirement is written in an active voice.\")\n",
        "        else:\n",
        "            feedback.append(\"FAIL: Requirement may be in a passive voice (contains 'should be').\")\n",
        "\n",
        "    # --- Rule Check 3: Check for the core \"shall\" statement ---\n",
        "    if \"shall\" in generated_text:\n",
        "        feedback.append(\"PASS: Requirement contains the mandatory keyword 'shall'.\")\n",
        "    else:\n",
        "        feedback.append(\"FAIL: Requirement is missing the mandatory keyword 'shall'.\")\n",
        "\n",
        "    # Calculate the final score\n",
        "    pass_count = sum(1 for note in feedback if note.startswith(\"PASS\"))\n",
        "    total_checks = len(feedback)\n",
        "\n",
        "    if total_checks == 0:\n",
        "        return \"N/A\", [\"No applicable rules found to score against.\"]\n",
        "\n",
        "    return f\"{pass_count}/{total_checks}\", feedback\n",
        "\n",
        "# def calculate_compliance_score(generated_text, retrieved_rules):\n",
        "#     \"\"\"\n",
        "#     Calculates a simple compliance score based on the retrieved rules.\n",
        "#     This function directly implements the \"Compliance Score\" metric from the thesis.\n",
        "#     \"\"\"\n",
        "#     score = 0\n",
        "#     total_possible_score = 0\n",
        "#     feedback = []\n",
        "\n",
        "#     # Rule Check 1: Check for the standard format\n",
        "#     template_guide = next((rule for rule in retrieved_rules if \"format:\" in rule), None)\n",
        "#     if template_guide:\n",
        "#         total_possible_score += 1\n",
        "#         if \"The system shall\" in generated_text and \"for the\" in generated_text:\n",
        "#             score += 1\n",
        "#             feedback.append(\"PASS: Requirement follows the standard 'The system shall...' format.\")\n",
        "#         else:\n",
        "#             feedback.append(\"FAIL: Requirement does not follow the standard format.\")\n",
        "\n",
        "#     # Rule Check 2: Check for active voice\n",
        "#     if any(\"active voice\" in rule for rule in retrieved_rules):\n",
        "#         total_possible_score += 1\n",
        "#         if \"should be\" not in generated_text:\n",
        "#             score += 1\n",
        "#             feedback.append(\"PASS: Requirement is written in an active voice.\")\n",
        "#         else:\n",
        "#             feedback.append(\"FAIL: Requirement may be in a passive voice (contains 'should be').\")\n",
        "\n",
        "#     # Rule Check 3: Check for specified user role\n",
        "#     if any(\"user role\" in rule for rule in retrieved_rules):\n",
        "#         total_possible_score += 1\n",
        "#         if \"for the user\" not in generated_text.lower() and \"for the\" in generated_text.lower():\n",
        "#             score += 1\n",
        "#             feedback.append(\"PASS: Requirement appears to specify a user role.\")\n",
        "#         else:\n",
        "#             feedback.append(\"FAIL: Requirement uses a generic role ('user') or is missing one.\")\n",
        "\n",
        "#     if total_possible_score == 0:\n",
        "#         return \"N/A\", [\"No applicable rules found to score against.\"]\n",
        "\n",
        "#     return f\"{score}/{total_possible_score}\", feedback\n",
        "# ===================================================================\n",
        "# CELL 5: Run on Multiple Requirements and Create (X, y) Examples\n",
        "# ===================================================================\n",
        "\n",
        "# --- Configuration ---\n",
        "num_samples_to_process = 10\n",
        "results_list = [] # List to store our (X, y) pairs\n",
        "\n",
        "print(\"=====================================================================\")\n",
        "print(f\"  RUNNING RAG PIPELINE to generate {num_samples_to_process} (X, y) examples  \")\n",
        "print(\"=====================================================================\")\n",
        "\n",
        "for idx, row in df_requirements.head(num_samples_to_process).iterrows():\n",
        "\n",
        "    original_req_text = row['text']\n",
        "    print(f\"\\n\\nProcessing Requirement #{idx + 1}...\")\n",
        "\n",
        "    # --- RAG Pipeline Steps ---\n",
        "    relevant_rules = retrieve_relevant_knowledge(original_req_text)\n",
        "    refined_requirement = generate_compliant_requirement_with_gemma(original_req_text, relevant_rules)\n",
        "    compliance_score, feedback_notes = calculate_compliance_score(refined_requirement, relevant_rules)\n",
        "\n",
        "    # --- Store the results ---\n",
        "    results_list.append({\n",
        "        'X_Input_Requirement': original_req_text,\n",
        "        'y_Output_Requirement': refined_requirement,\n",
        "        'Compliance_Score': compliance_score,\n",
        "        'Retrieved_Context_Rules': \" | \".join(relevant_rules) # Join rules into a single string\n",
        "    })\n",
        "\n",
        "    # --- Print the output for viewing ---\n",
        "    print(\"---------------------------------------------------------------------\")\n",
        "    print(f\"[INPUT - X] Original:\\n'{original_req_text}'\")\n",
        "    print(f\"\\n[OUTPUT - y] Refined:\\n'{refined_requirement}'\")\n",
        "    print(f\"\\n[VALIDATION] Compliance Score: {compliance_score}\")\n",
        "    print(\"=====================================================================\")\n",
        "\n",
        "# --- Create a final DataFrame with the results ---\n",
        "df_results = pd.DataFrame(results_list)\n",
        "\n",
        "# --- Save the results to a new CSV file in the processed data folder ---\n",
        "output_examples_path = '/content/X_y_examples.csv'\n",
        "df_results.to_csv(output_examples_path, index=False)\n",
        "\n",
        "print(f\"\\nSuccessfully generated and saved {len(df_results)} (X, y) examples to '{output_examples_path}'\")\n",
        "\n",
        "# Trigger a download of this new file\n",
        "from google.colab import files\n",
        "files.download(output_examples_path)\n",
        "# ===================================================================\n",
        "\n",
        "# --- Configuration ---\n",
        "num_samples_to_process = 5\n",
        "\n",
        "print(\"=====================================================================\")\n",
        "print(f\"       RUNNING RAG PIPELINE DEMO on the First {num_samples_to_process} Requirements      \")\n",
        "print(\"=====================================================================\")\n",
        "\n",
        "\n",
        "# # ===================================================================\n",
        "# # CELL 5: Run the Full End-to-End Demo with Validation\n",
        "# # --- Loop through the first N samples of the DataFrame ---\n",
        "# for idx, row in df_requirements.head(num_samples_to_process).iterrows():\n",
        "\n",
        "#     original_req_text = row['text']\n",
        "\n",
        "#     print(f\"\\n\\nProcessing Requirement #{idx + 1}...\")\n",
        "#     print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "#     # --- Step 1: Input ---\n",
        "#     print(f\"[INPUT] Original Requirement:\\n'{original_req_text}'\")\n",
        "\n",
        "#     # --- Step 2: Retrieval ---\n",
        "#     print(\"\\n[STEP 1 - RETRIEVAL] Finding the most relevant rules from the knowledge base...\")\n",
        "#     relevant_rules = retrieve_relevant_knowledge(original_req_text)\n",
        "#     print(\"  - Found the following rules:\")\n",
        "#     for rule in relevant_rules:\n",
        "#         print(f\"    - {rule}\")\n",
        "\n",
        "#     # --- Step 3: Generation ---\n",
        "#     print(\"\\n[STEP 2 - GENERATION] Sending the original requirement and retrieved rules to Gemma for refinement...\")\n",
        "#     refined_requirement = generate_compliant_requirement_with_gemma(original_req_text, relevant_rules)\n",
        "\n",
        "#     # --- Step 4: Validation ---\n",
        "#     print(\"\\n[STEP 3 - VALIDATION] Calculating the automated compliance score...\")\n",
        "#     compliance_score, feedback_notes = calculate_compliance_score(refined_requirement, relevant_rules)\n",
        "#     print(f\"  - Compliance Score: {compliance_score}\")\n",
        "#     for note in feedback_notes:\n",
        "#         print(f\"    - {note}\")\n",
        "\n",
        "#     # --- Step 5: Final Output ---\n",
        "#     print(\"\\n---------------------------------------------------------------------\")\n",
        "#     print(f\"[OUTPUT] Final, Compliant Requirement:\\n'{refined_requirement}'\")\n",
        "#     print(\"=====================================================================\")"
      ]
    }
  ]
}